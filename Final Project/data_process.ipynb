{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vr/anaconda3/envs/2023adl-hw3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "import transformers\n",
    "import argparse\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji_in_string(input_string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                            u\"\\U00002700-\\U000027BF\"  # Dingbats\n",
    "                            u\"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "                            u\"\\U00002600-\\U000026FF\"  # Miscellaneous Symbols\n",
    "                            u\"\\U0001F300-\\U0001F5FF\"  # Miscellaneous Symbols And Pictographs\n",
    "                            u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "                            u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "                            u\"\\U0001F680-\\U0001F6FF\"  # Transport and Map Symbols\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', input_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_files(path, remove_emoji = False) -> pd.DataFrame:\n",
    "    '''\n",
    "    Returns a dataframe of root directory, file names, and content(list) of json files\n",
    "    '''\n",
    "    def preprocessing(content, remove_emoji):\n",
    "        content = copy.deepcopy(content)\n",
    "        for record in content:\n",
    "            # character to str\n",
    "            if type(record['votes']) == str:\n",
    "                if '萬' in record['votes']:\n",
    "                    record['votes'] = int(record['votes'].replace('萬', '')) * 10000\n",
    "            # emoji remove\n",
    "            if remove_emoji:\n",
    "                record['video_title'] = remove_emoji_in_string(record['video_title'])\n",
    "                record['video_description'] = remove_emoji_in_string(record['video_description'])\n",
    "                record['comment_text'] = remove_emoji_in_string(record['comment_text'])\n",
    "        return content\n",
    "\n",
    "    roots = []\n",
    "    file_names = []\n",
    "    contents = []\n",
    "    # Fast return if the path is a file\n",
    "    if path.endswith('.json'):\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            content = json.load(f)\n",
    "        content = preprocessing(content,remove_emoji)\n",
    "        return pd.DataFrame({'root': [path], 'file_name': [path.split('/')[-1]], 'content': [content]})\n",
    "    \n",
    "    # Get the root, file names, and content\n",
    "    for root, dirnames, filenames in os.walk(path):\n",
    "        for file in filenames:\n",
    "            if file.endswith('.json') and file != \"star_record.json\":\n",
    "                with open(os.path.join(root,file), 'r', encoding='utf-8') as f:\n",
    "                    content = json.load(f)\n",
    "                content = preprocessing(content,remove_emoji)\n",
    "                # create dataframe\n",
    "                roots.append(root)\n",
    "                file_names.append(file)\n",
    "                contents.append(content)\n",
    "    return pd.DataFrame({'root': roots, 'file_name': file_names, 'content': contents})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_selection(file_info: pd.DataFrame, num_video_per_channel = None, select = True, seed = None) -> pd.DataFrame :\n",
    "    '''\n",
    "    Randomly select data from each file and return a new dataframe of training data\n",
    "    num_video_per_channel: number of video to select from each channel. If None, select all videos\n",
    "    '''\n",
    "    random.seed(seed)\n",
    "    moods = ['like','happiness','sadness','anger','fear','surprise','disgust']\n",
    "    \n",
    "    datalist = []\n",
    "    channels = file_info['root'].unique()\n",
    "    for channel in channels:\n",
    "        videos = file_info.loc[file_info['root'] == channel, ['file_name','content']]\n",
    "        if num_video_per_channel is not None:\n",
    "            videos = videos.sample(n = num_video_per_channel, random_state = seed).reset_index(drop=True)\n",
    "        for vid in videos.index:\n",
    "            content = pd.DataFrame(videos.loc[vid,'content'])\n",
    "            if content.empty:\n",
    "                continue\n",
    "            if select:\n",
    "                for mood in moods:\n",
    "                    if  content.loc[content['mood'] == mood].size < 1: \n",
    "                        continue\n",
    "                    pick_data = content.loc[content['mood'] == mood].sample(n = 1, random_state = None).reset_index(drop=True)\n",
    "                    datalist.append(pick_data)\n",
    "            else:\n",
    "                datalist.append(content)\n",
    "    return pd.concat(datalist, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(path, num_video_per_channel = None, remove_emoji = True, select = True, seed = None):\n",
    "    '''\n",
    "    Returns a dataset of json files\n",
    "    '''\n",
    "    file_info = read_json_files(path, remove_emoji)\n",
    "    data_df = data_selection(file_info, num_video_per_channel, select=select, seed=seed)\n",
    "    return Dataset.from_pandas(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(title:str, description:str, star_num:str, mood:str) -> str:\n",
    "    '''Format the instruction as a prompt for LLM.'''\n",
    "\n",
    "    comment_type = '正面評論' if star_num.split()[1] in ['4', '5'] else '負面評論' if star_num.split()[1] in ['1', '2'] else '中立評論'\n",
    "    moods = ['like','happiness','sadness','anger','fear','surprise','disgust']\n",
    "    ch_moods = ['喜歡','開心','難過','生氣','害怕','驚訝','厭惡']\n",
    "    if mood in moods:\n",
    "        mood = ch_moods[moods.index(mood)]\n",
    "    \n",
    "    return f\"你是人工智慧助理，以下是用戶和人工智能助理之間的對話。你要對用戶的問題提供有用、詳細的回答。\\\n",
    "USER: 請幫這部影片生出對應需求的{comment_type}。影片標題:[{title}]。影片敘述:[{description}]。需求情感:[{mood}]。\\\n",
    "ASSISTANT:\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    PATH = \"./train_data\"\n",
    "    dataset = prepare_dataset(PATH,5,seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'video_id': 'mJloNfHLUVU', 'video_title': '如何判斷誰是邊緣人', 'video_description': '遊走在你的身邊，神出鬼沒，像空氣一般自由飄散\\n看似被世人隔絕在外，卻又不時從角落散發出孤傲而獨立的清高氣息\\n這，就是邊緣人的魅力所在...', 'cid': 'UgyscGkwCygAXAFM1oh4AaABAg', 'comment_text': '0:46 但我是 \"Must! Go! Faster!\"', 'votes': 0, 'time': 1670659208.279021, 'star_num': 'star 5', 'mood': 'happiness'}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(dataset[90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adl-hw3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
